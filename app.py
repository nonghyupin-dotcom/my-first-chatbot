import streamlit as st
import tempfile
import os
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.embeddings import HuggingFaceEmbeddings

# 1. ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ AI ìš©ì–´ ì±—ë´‡", page_icon="ğŸ“˜")
st.title("ğŸ“˜ AI ìš©ì–´ 100ì„  ì±—ë´‡")

# --- Secretsì—ì„œ í‚¤ ê°€ì ¸ì˜¤ê¸° ---
if "GOOGLE_API_KEY" in st.secrets:
    google_api_key = st.secrets["GOOGLE_API_KEY"].strip()
else:
    st.error("Secretsì— API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# 2. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“‚ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì„ íƒ", type="pdf")
    
    if google_api_key.startswith("AIza"):
        st.caption("âœ… Gemini LLM ì—°ê²° ëŒ€ê¸° ì¤‘")

# 3. ë©”ì¸ ë¡œì§
if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    # (1) ë¬¸ì„œ í•™ìŠµ (ë¡œì»¬ CPU ì‚¬ìš©)
    with st.spinner("AIê°€ ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (ì„œë²„ì—ì„œ ì§ì ‘ ì²˜ë¦¬)"):
        try:
            loader = PyMuPDFLoader(tmp_file_path)
            pages = loader.load()
            
            # ë¬´ë£Œ ë¡œì»¬ ì„ë² ë”©
            embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
            
            vectorstore = FAISS.from_documents(pages, embeddings)
            st.success(f"âœ… {len(pages)}í˜ì´ì§€ ë¬¸ì„œ í•™ìŠµ ì™„ë£Œ! ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
        except Exception as e:
            st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            st.stop()

    # (2) LLM ì—°ê²° (ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤!)
    # gemini-pro -> gemini-1.5-flash (ìµœì‹  ëª¨ë¸ë¡œ ë³€ê²½)
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=google_api_key)
    
    query = st.chat_input("ê¶ê¸ˆí•œ ìš©ì–´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”!")
    
    if query:
        with st.chat_message("user"):
            st.write(query)
        
        # RAG ì²´ì¸ ê°€ë™
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
        )
        
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                result = qa_chain.invoke(query)
                with st.chat_message("assistant"):
                    st.write(result['result'])
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

elif not uploaded_file:
    st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì±—ë´‡ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
