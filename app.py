import streamlit as st
import tempfile
import os
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

# 1. ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ AI ìš©ì–´ ì±—ë´‡", page_icon="ğŸ“˜")
st.title("ğŸ“˜ AI ìš©ì–´ 100ì„  ì±—ë´‡")

# --- [í•µì‹¬] Secretsì—ì„œ í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ ---
if "GOOGLE_API_KEY" in st.secrets:
    google_api_key = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("ì„¤ì •(Settings) > Secrets ë©”ë‰´ì— API í‚¤ë¥¼ ì €ì¥í•´ì£¼ì„¸ìš”!")
    st.stop()

# 2. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“‚ ë¬¸ì„œ ì—…ë¡œë“œ")
    st.write("í•™ìŠµí•  PDF íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì„ íƒ", type="pdf")
    
    if google_api_key.startswith("AIza"):
        st.success("âœ… ì„œë²„ì™€ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")

# 3. ë©”ì¸ ë¡œì§
if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    # ë¬¸ì„œ í•™ìŠµ
    with st.spinner("AIê°€ ë¬¸ì„œë¥¼ ì½ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            loader = PyMuPDFLoader(tmp_file_path)
            pages = loader.load()
            embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=google_api_key)
            vectorstore = FAISS.from_documents(pages, embeddings)
            st.success("ë¬¸ì„œ í•™ìŠµ ì™„ë£Œ! ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

    # ì§ˆë¬¸ ë‹µë³€
    llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=google_api_key)
    query = st.chat_input("ê¶ê¸ˆí•œ ìš©ì–´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”!")
    
    if query:
        with st.chat_message("user"):
            st.write(query)
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
        )
        
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            result = qa_chain.invoke(query)
            with st.chat_message("assistant"):
                st.write(result['result'])

elif not uploaded_file:
    st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì±—ë´‡ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
