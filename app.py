import streamlit as st
import tempfile
import os
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.embeddings import HuggingFaceEmbeddings # ë¡œì»¬ ì„ë² ë”© ë„êµ¬ ì¶”ê°€

# 1. ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ AI ìš©ì–´ ì±—ë´‡", page_icon="ğŸ“˜")
st.title("ğŸ“˜ AI ìš©ì–´ 100ì„  ì±—ë´‡")

# --- Secretsì—ì„œ í‚¤ ê°€ì ¸ì˜¤ê¸° ---
if "GOOGLE_API_KEY" in st.secrets:
    google_api_key = st.secrets["GOOGLE_API_KEY"].strip()
else:
    st.error("Secretsì— API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# 2. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“‚ ë¬¸ì„œ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì„ íƒ", type="pdf")
    
    if google_api_key.startswith("AIza"):
        st.success("âœ… Gemini LLM ì—°ê²° ëŒ€ê¸° ì¤‘")

# 3. ë©”ì¸ ë¡œì§
if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    # (1) ë¬¸ì„œ í•™ìŠµ (ì—¬ê¸°ê°€ í•µì‹¬ ë³€ê²½!)
    # êµ¬ê¸€ APIë¥¼ ì•ˆ ì“°ê³ , ì„œë²„ ìì²´ CPUë¡œ ë¬´ë£Œ ë³€í™˜í•©ë‹ˆë‹¤. (ì†ë„ ì œí•œ ì—†ìŒ)
    with st.spinner("AIê°€ ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (ì„œë²„ì—ì„œ ì§ì ‘ ì²˜ë¦¬)"):
        try:
            loader = PyMuPDFLoader(tmp_file_path)
            pages = loader.load()
            
            # ê°€ë³ê³  ë¹ ë¥¸ ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (all-MiniLM-L6-v2)
            # ì´ ê³¼ì •ì€ êµ¬ê¸€ API í‚¤ê°€ í•„ìš” ì—†ê³ , íšŸìˆ˜ ì œí•œë„ ì—†ìŠµë‹ˆë‹¤.
            embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
            
            vectorstore = FAISS.from_documents(pages, embeddings)
            st.success(f"âœ… {len(pages)}í˜ì´ì§€ ë¬¸ì„œ í•™ìŠµ ì™„ë£Œ! ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
        except Exception as e:
            st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            st.stop()

    # (2) LLM ì—°ê²° (ë‹µë³€ì€ ë˜‘ë˜‘í•œ êµ¬ê¸€ Geminiê°€ ë‹´ë‹¹)
    llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=google_api_key)
    query = st.chat_input("ê¶ê¸ˆí•œ ìš©ì–´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”!")
    
    if query:
        with st.chat_message("user"):
            st.write(query)
        
        # RAG ì²´ì¸ ê°€ë™
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
        )
        
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                result = qa_chain.invoke(query)
                with st.chat_message("assistant"):
                    st.write(result['result'])
            except Exception as e:
                # ë§Œì•½ ì—¬ê¸°ì„œ 429 ì—ëŸ¬ê°€ ë‚˜ë©´ ê·¸ê±´ ì±„íŒ…ì„ ë„ˆë¬´ ë¹¨ë¦¬ ì³ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤.
                if "429" in str(e):
                    st.warning("ì•—! ë‹µë³€ ìƒì„± ì†ë„ê°€ ë„ˆë¬´ ë¹¨ë¼ìš”. 10ì´ˆë§Œ ì‰¬ì—ˆë‹¤ê°€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”. (ë¬´ë£Œ ê³„ì • ì œí•œ)")
                else:
                    st.error(f"ë‹µë³€ ì—ëŸ¬: {e}")

elif not uploaded_file:
    st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì±—ë´‡ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
